from collections import Counter
from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks, EditedNearestNeighbours, ClusterCentroids, AllKNN
from sklearn.preprocessing import OrdinalEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.dummy import DummyClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, fbeta_score, roc_auc_score, matthews_corrcoef
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from tabulate import tabulate 
import pandas as pd
import numpy as np

# For simplicity logging for this script was done through bash piping ("python3 undersamplers.py > logs/undersamplers.txt")

categorical_columns = [
    'impact.baseMetricV2.cvssV2.accessVector', 
    'impact.baseMetricV2.cvssV2.authentication', 
    'impact.baseMetricV2.cvssV2.accessComplexity',
    'impact.baseMetricV2.cvssV2.integrityImpact',
    'impact.baseMetricV2.cvssV2.confidentialityImpact',
    'impact.baseMetricV2.cvssV2.availabilityImpact',
    'impact.baseMetricV2.severity',
    'impact.baseMetricV2.obtainAllPrivilege',
    'impact.baseMetricV2.obtainUserPrivilege',
    'impact.baseMetricV2.obtainOtherPrivilege',
    'impact.baseMetricV2.userInteractionRequired'
]

def data_preparation(df):

    # Dropping columns that are not needed
    df = df.drop(labels="Unnamed: 0", axis=1)
    df = df.drop(labels="impact.baseMetricV2.acInsufInfo", axis=1)    # Clearing the dataset from NA values
    df = df[df['impact.baseMetricV2.userInteractionRequired'].notna()]
    encoder = OrdinalEncoder()
    df[categorical_columns] = encoder.fit_transform(df[categorical_columns])
    X = df.iloc[:,22:36].values  
    y = df.iloc[ :, 5].values 
    return X, y

def cross_validate(classifier, X_train, y_train):
    X_train = pd.DataFrame(X_train)
    y_train = pd.Series(y_train)
    n_folds = 10
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    cv_scores = []

    for fold, (train_index, test_index) in enumerate(kf.split(X_train)):
        X_train_fold, y_train_fold = X_train.iloc[train_index], y_train.iloc[train_index]
        X_test_fold, y_test_fold = X_train.iloc[test_index], y_train.iloc[test_index]
        classifier.fit(X_train_fold, y_train_fold)
        y_test_pred = classifier.predict(X_test_fold)
        fold_score = f1_score(y_test_fold, y_test_pred)
        cv_scores.append(fold_score)
        
    mean_cv_score = np.mean(cv_scores)
    print('Cross-validation score (f1-measure) for classifier {}: {:.3f})'.format(str(type(classifier)).split(".")[-1][:-2],mean_cv_score))

def my_scorer(classifier, X, y):    
    y_pred = classifier.predict(X)
    cm = confusion_matrix(y, y_pred)
    tn = cm[0, 0]
    fp = cm[0, 1]
    fn = cm[1, 0]
    tp = cm[1, 1]
    inspection_rate = (tp + fp) / (tp + tn + fp + fn)
    precision = precision_score(y, y_pred, zero_division=1)
    recall = recall_score(y, y_pred)
    accuracy = accuracy_score(y, y_pred)
    f1 = f1_score(y, y_pred)
    f2 = fbeta_score(y, y_pred, beta=2) 
    roc_auc = roc_auc_score(y, y_pred)
    mcc = matthews_corrcoef(y, y_pred)

    headers = ["Metric", "Value"]
    rows = [
        ["Classifier", str(type(classifier)).split(".")[-1][:-2]],
        ["Precision", precision],
        ["Recall", recall],
        ["Accuracy", accuracy],
        ["Inspection Rate", inspection_rate],
        ["F1-score", f1],
        ["F2-score", f2],
        ["ROC-AUC", roc_auc],
        ["MCC", mcc]
    ]    
    print("{}\n".format(tabulate(rows, headers=headers)))

if __name__ == "__main__":
    undersamplers = [
    RandomUnderSampler(random_state=42),
    NearMiss(version=1),
    TomekLinks(),
    NearMiss(version=2),
    EditedNearestNeighbours(),
    NearMiss(version=3),
    ClusterCentroids(random_state=42),
    AllKNN()
    ]
    # Dataset import and data preparation phase
    df = pd.read_csv('../../data/final/dataset.csv')  
    X, y = data_preparation(df)
    # Splitting the dataset in training and test set
    test_set_size = 0.2
    X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= test_set_size, random_state=0) 
    results = []
    for sampler in undersamplers: 

        X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)
        print(f"\n\nUndersampling method: {sampler.__class__.__name__}")
        print(f"Training set before undersampling: {Counter(y_train)}")
        print(f"Training set after undersampling: {Counter(y_resampled)}")
        print(f"Test set: {Counter(y_test)}")

        # Random forest
        rf_classifier = RandomForestClassifier(n_jobs=-1)
        rf_classifier.fit(X_resampled, y_resampled)
        cross_validate(rf_classifier, X_resampled, y_resampled)
        my_scorer(rf_classifier, X_test, y_test)

        # SVM
        svm_classifier = svm.SVC()
        svm_classifier.fit(X_resampled, y_resampled)
        cross_validate(svm_classifier, X_resampled, y_resampled)
        my_scorer(svm_classifier, X_test, y_test)

        # Decision tree
        tree_classifier = DecisionTreeClassifier(random_state=42)
        tree_classifier.fit(X_resampled, y_resampled)
        cross_validate(tree_classifier, X_resampled, y_resampled)
        my_scorer(tree_classifier, X_test, y_test)

        # Naive Bayes
        nb_classifier = BernoulliNB()
        nb_classifier.fit(X_resampled, y_resampled)
        cross_validate(nb_classifier, X_resampled, y_resampled)
        my_scorer(nb_classifier, X_test, y_test)
        
        opt_classifier = DummyClassifier(strategy="constant", constant = 0)
        opt_classifier.fit(X_resampled, y_resampled)
        cross_validate(opt_classifier, X_resampled, y_resampled)
        my_scorer(opt_classifier, X_test, y_test)

        pes_classifier = DummyClassifier(strategy="constant", constant = 1)
        pes_classifier.fit(X_resampled, y_resampled)
        cross_validate(pes_classifier, X_resampled, y_resampled)
        my_scorer(pes_classifier, X_test, y_test)