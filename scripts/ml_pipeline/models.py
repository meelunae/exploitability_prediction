from collections import Counter
from imblearn.under_sampling import RandomUnderSampler, NearMiss, TomekLinks, EditedNearestNeighbours, ClusterCentroids, AllKNN
from imblearn.over_sampling import SMOTE, RandomOverSampler
from sklearn.ensemble import RandomForestClassifier
from sklearn.dummy import DummyClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV, KFold, cross_val_score
import numpy as np

# Hyperparameter grids for the single models
def param_grids(model):

    if isinstance(model, DecisionTreeClassifier):
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'splitter': ['best', 'random'],
            'max_depth': [3, 4, 5, 6, 10],
            'min_samples_split': [2, 3, 4],
            'min_samples_leaf': [1, 2, 3],
            'max_features': [None, 'sqrt', 'log2'],
            'max_leaf_nodes': [None, 10, 20, 30],
            'min_impurity_decrease': [0.0, 0.1, 0.2]
        }

    if isinstance(model, RandomForestClassifier):
        param_grid = {
            'n_estimators': np.arange(100, 500, step=100),
            'max_features': ["sqrt", "log2"],
            'max_depth': list(np.arange(10, 50, step=10)) + [None],
            'min_samples_split':  np.arange(2, 10, step=2),
            'min_samples_leaf': [1, 2],
            'bootstrap': [True, False]
        }

    if isinstance(model, SVC):
        param_grid = {
            'C': [0.1, 1, 5, 10], 
            'gamma': [1, 0.1, 0.01, 0.001, 0.0001],
            'kernel': ['rbf', 'linear']
        } 
        
    if isinstance(model, BernoulliNB):
        param_grid = {
            'alpha': [0.01, 0.1, 0.5, 1.0],
            'fit_prior': [True, False],
        }
    return param_grid

# Running data processing and GridSearchCV (with 5 folds) inside an outer loop of 10-fold cross validation for more accurate results
def hp_tuning(clf, X, y):
    print(f"Training set: {Counter(y)}")
    n_folds = 10
    outer_kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    outer_scores = []
    for train_index, test_index in outer_kf.split(X):
        under_sampler = NearMiss(version=2)
        print(f"Undersampling training data using {under_sampler.__class__.__name__} algorithm")
        X_train_outer, X_test_outer = X[train_index], X[test_index]
        y_train_outer, y_test_outer = y[train_index], y[test_index]
        print(f"Training set before undersampling: {Counter(y_train_outer)}")
        X_resampled, y_resampled = under_sampler.fit_resample(X_train_outer, y_train_outer)
        print(f"Training set after undersampling: {Counter(y_resampled)}")

        inner_kf = KFold(n_splits=5, shuffle=True, random_state=42)
        grid_search = GridSearchCV(clf, param_grids(clf), scoring='f1', n_jobs=-1, cv=inner_kf, verbose=3)
        grid_search.fit(X_resampled, y_resampled)
        best_clf = grid_search.best_estimator_
        outer_score = cross_val_score(best_clf, X_test_outer, y_test_outer, scoring='f1', cv=inner_kf)
        outer_scores.append(outer_score.mean())
        del X_train_outer, X_test_outer, y_train_outer

    print("Outer CV Scores:", outer_scores)
    print("Mean Outer CV Score:", np.mean(outer_scores))
    return outer_scores

def samplers_evaluation(clf, X, y):
    print(f"Running algorithms on classifier {clf.__class__.__name__}")
    print(f"Set size before sampling algorithm (based on the y array): {Counter(y)}")
    samplers = [
        RandomUnderSampler(sampling_strategy="majority", random_state=42),
        NearMiss(version=1),
        TomekLinks(),
        NearMiss(version=2),
        EditedNearestNeighbours(),
        NearMiss(version=3),
        ClusterCentroids(random_state=42),
        AllKNN(),
        SMOTE(),
        RandomOverSampler(sampling_strategy="minority", random_state=42)
    ]

    for sampler in samplers:
        X_res, y_res = sampler.fit_resample(X, y)
        print(f"Currently evaluating: {sampler.__class__.__name__}")
        print(f"Set size after sampling algorithm (based on the y array): {Counter(y_res)}")
        print(f"Cross validation (on 5 folds) f1-measure scores: {cross_val_score(clf, X_res, y_res, cv=5, scoring='f1')}\n")
        del X_res, y_res