import csv
from os import listdir
import os
from os.path import isfile, join
import requests
import re
import zipfile
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.chrome.options import Options

import bs4 as bs
import chromedriver_binary


exploits_dict = {"Exploit": "CVE code"}
results_file = open("../../data/exploitdb/dataset.csv", "w")
results_list = [('Exploit file path:', 'Description', "ExploitDB ID", "CVE", "Author", "Type", "Platform", "Date")]
results_writer = csv.writer(results_file)
to_ignore = ["README.md", "LICENSE.md", "files_shellcodes.csv", "files_exploits.csv", "searchsploit", ".searchsploit_rc", "exploits", ".DS_Store"]
print("Getting latest update of the ExploitDB repo...")
r = requests.get("https://github.com/offensive-security/exploitdb/archive/refs/heads/master.zip")
open('master.zip', 'wb').write(r.content)
print("Extracting downloaded archive...")
with zipfile.ZipFile('master.zip', 'r') as zip_ref:
    zip_ref.extractall()
print("Removing downloaded zip file after extraction...")
os.remove('master.zip')

os.chdir(os.getcwd() + '/exploitdb-master') # All data is unzipped in exploitdb-master so I move there to access it easily
print("Opening files_exploits.csv to combine CSVs...")
with open('files_exploits.csv', mode='r') as csv_file:
    csv_reader = csv.DictReader(csv_file)
    for row in csv_reader:
        exploits_dict["{}".format(row["file"])] = row["description"] 


try:
    counter = 0
    print("Locating exploit PoCs with valid CVE code(s)...")
    for root, subdirectories, files in os.walk(os.getcwd()):
        [subdirectories.remove(d) for d in list(subdirectories) if d == "shellcodes"] # I'm only interested in the exploits subfolder of the repo root, so I'm excluding shellcodes from my scan
        for file in files:
                with open(os.path.join(root, file)) as f:
                    parsed_filename = re.sub(r'^.*?exploitdb-master/', '', f.name)
                    if parsed_filename in to_ignore:
                        continue;
                    edb_id = parsed_filename.split("/")[-1].split(".")[0]
                    url = "https://www.exploit-db.com/exploits/"+edb_id
                    print("Analyzing {} ({} of {})".format(url, counter, len(exploits_dict)))
                    try:
                        options = Options()
                        options.add_argument("--headless")
                        browser = webdriver.Chrome(options=options)
                        browser.get(url)
                        soup = bs.BeautifulSoup(browser.page_source,'lxml')
                        field_names = soup.find_all("h4", class_="info-title")
                        field_values =  soup.find_all("h6", class_="stats-title")
                        t = (parsed_filename, exploits_dict[parsed_filename])
                        for name, value in zip(field_names, field_values):
                            t = (*t, value.text.strip())
                        print(t)
                        results_list.append(t)
                        browser.quit()
                        counter += 1
                    except Exception as e:
                        print(e)
except Exception as e:
    print(e)
print("Saving {} results to target CSV...".format(len(results_list)))
results_writer.writerows(results_list) # I have the full file path and I only need the substring starting from exploits/
results_file.close()
print("Done!")
