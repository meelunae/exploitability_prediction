import csv
from os import listdir
import os
from os.path import isfile, join
import requests
import sys
import re
import zipfile
from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.chrome.options import Options
import concurrent.futures
import bs4 as bs
import chromedriver_binary

num = 1
exploits_dict = {"Exploit": "CVE code"}
results_file = open("../../data/exploitdb/dataset.csv", "w")
results_list = [('Exploit file path:', 'Description', "ExploitDB ID", "CVE", "Author", "Type", "Platform", "Date")]
results_writer = csv.writer(results_file)
to_ignore = ["README.md", "LICENSE.md", "files_shellcodes.csv", "files_exploits.csv", "searchsploit", ".searchsploit_rc", "exploits", ".DS_Store"]

def parse(f):
    global num
    parsed_filename = re.sub(r'^.*?exploitdb-master/', '', f.name)
    if parsed_filename in to_ignore:
        return;
    edb_id = parsed_filename.split("/")[-1].split(".")[0]
    url = "https://www.exploit-db.com/exploits/"+edb_id
    num +=1
    print("Analyzing {} ({} of {})".format(url, num, len(exploits_dict)))
    try:
        global results_list
        options = Options()
        options.add_argument("--headless")
        browser = webdriver.Chrome(options=options)
        browser.get(url)
        soup = bs.BeautifulSoup(browser.page_source,'lxml')
        field_values =  soup.find_all("h6", class_="stats-title")
        t = (parsed_filename, exploits_dict[parsed_filename])
        for value in field_values:
            t = (*t, value.text.strip())
        browser.quit()
        results_list.append(t)
    except Exception as e:
        print(e)

print("Getting latest update of the ExploitDB repo...")
r = requests.get("https://github.com/offensive-security/exploitdb/archive/refs/heads/master.zip")
open('master.zip', 'wb').write(r.content)
print("Extracting downloaded archive...")
with zipfile.ZipFile('master.zip', 'r') as zip_ref:
    zip_ref.extractall()
print("Removing downloaded zip file after extraction...")
os.remove('master.zip')

os.chdir(os.getcwd() + '/exploitdb-master') # All data is unzipped in exploitdb-master so I move there to access it easily
print("Opening files_exploits.csv to combine CSVs...")
with open('files_exploits.csv', mode='r') as csv_file:
    csv_reader = csv.DictReader(csv_file)
    for row in csv_reader:
        exploits_dict["{}".format(row["file"])] = row["description"] 

try:
    print("Locating exploit PoCs with valid CVE code(s)...")
    count = 0
    for root, subdirectories, files in os.walk(os.getcwd()):
        [subdirectories.remove(d) for d in list(subdirectories) if d == "shellcodes"] # I'm only interested in the exploits subfolder of the repo root, so I'm excluding shellcodes from my scan
        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
            for file in files:
                    with open(os.path.join(root, file)) as f:
                        executor.submit(parse, f)
                        
except Exception as e:
    print(e)
print("Saving {} results to target CSV...".format(len(results_list)))
results_writer.writerows(results_list) # I have the full file path and I only need the substring starting from exploits/
results_file.close()
print("Done!")
